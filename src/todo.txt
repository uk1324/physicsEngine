Editor
Evaluating expressions in ImGui inputs. Could also include access to variables.
Sequencer system for cutscenes. Triggers, Camera panning action
The scene hierarchy should be a seperate part of the file format. Entites should still be stored in arrays.
This makes it easier to remove it from the final file and also import it is easier.
Chain editor. Half spaces or lines?
Proceduraly generating textures under the chain.

Modifiers
In the editor could store a map<Entity, Modifier>.

Modifiers a just functions that are updated every frame and get the entity as the input.
They could be used to make motors(set velocity of something). Could also integrate a scripting language for making more complicated scripts.

Maybe add a unit type system for the langage. mass * length = velocity

To generatae angles of a convex poylgon could generate a sum of angles that are less than 90 and then normalize it.
These ides wouldn't work, but are cool. Generating a point on a sphere. Angles or generate on cube and then normalize.

Maybe make a immediate mode style interface for the editor.
if (Circle(&pos)) {

}

Create a scoped std::ostream that writes tabs on a newline. 

Make things like this not happen.
	result["staticWorldSpaceAnchorOrBodyAnchorB"] = 	if (const auto value = std::get_if<Vec2>(&staticWorldSpaceAnchorOrBodyAnchorB)){
		{ { "type", Vec2 }, 
		{ { "value", { { "x", staticWorldSpaceAnchorOrBodyAnchorB.x }, { "y", staticWorldSpaceAnchorOrBodyAnchorB.y } } }
	 }
;

Snap the passed cursor pos to important features like corners

Have a menu that allows saving sublevels something similar to prefabs in unity. And maybe make creating things like shapes only be a tab in the menu for those things.

Maybe make a menu appear when two entities are selected that shows that they can be connected with a joint. Maybe show the menu only after something is held down for some amount of time.

For modifiers store a map of entiy to modifier. Maybe also store the entity in the modifier so the it knows it should and or remove itself from the list.

Distance joint modifier that changes the distance.

// https://developer.valvesoftware.com/wiki/Physics_Entities_on_Server_%26_Client
Collision groups. Group zero means collide with everything. When loading a level could check what groups are already used. Could have an option to color things in different groups differently. Could make making things static by making the group they are in static. Or maybe just something like static groups idk. Groups could either be represented by numbers or colors.
A better way to implement this would be to have collision layers. Collision groups would define which layers can collide with eachother. Relational database. Custom gui for selecting the collision layer of body. Could allow naming layers and the gui could display the names. It would probably be better to call it after calling the gui method of the object because it needs to access the names of the collision layers and passing that into a function would require some modifications.
Either store pairs or for each layer store an list. Creating a kind of matrix.
NoCollisionConstraint 

Maybe make a controallble camera that can be used in different parts of the engine. Maybe make some features disabable like grabbing.

Maybe make adding things like joints separate tools. If they are selected then when a body is clicked a joint is started when another one is the joint ends.

Read about more generic seraizliation systems. Versioning. When adding a new field assign which version it belongs to. This would allow binary loading of data.

When drawing colliders could save the velocitites and use hermite interpolation.

Select brush

Make the entity system immediate mode. Callbacks seem more error prone. 
Control the entity access with optional types (this could also be done in a callback system, but then you are doing twice the work). Having to always check that the entity is alive seems like a good idea. Deleting entites can also be done in an immediate way. The acceleration structures could just check if the entites it stores are alive. There is no need to store a list of removed entites because the indexes can't get invalidated.
Adding entites can invalidate references. So to avoid mistakes it is probably better to buffer it.
In my previous entity systems the order of the entites could change when deleting so the deletion had to be delayed to the end of the frame.

Read particle dynamics again
https://www.cs.cmu.edu/~baraff/sigcourse/

When interpolating between 2 signed distance fields the colors should also be interpolated. Interpolating between colors might look better when interpolating between the curves.

Gauss sidel is a method for solving systems of equations.
In the case of a linear system of equations the process looks like this.
Frist select some random initial values.
Solve the first equation for the first unknown. Pass the value to the subsequent equations and repeat with the other equations.
This method doesn't always converge.
The solutions to a linear system of equations can be interpreted as an intersection of n hyperplanes.
Soultions of each equation represents a plane. The gauss seidel method esentially projects (shortest distance) a random point onto the subsequent planes. This often gets coloser to the point of intersection of the hyperplanes.
https://www.quora.com/What-is-the-difference-between-the-Gauss-Seidel-and-the-Jacobi-Method
https://erkaman.github.io/posts/jacobi_and_gauss_seidel.html
// It might not actually be always a straight projection idk.
https://shahriyarshahrabi.medium.com/gentle-introduction-to-fluid-simulation-for-programmers-and-technical-artists-7c0045c40bac
If it were a projection onto the line with on the path using only x or y then it would probably create a spiral. And it would work if dot(a, b) == 0.

Inverse of matrix using cramer's rule

Joining the triangles of a triangulated shape to improve the efficiency of the collider. Might need to construct some conectiveness graph, either during the triangulation algorithm or after. The simplest way would probably be a greedy algorithm.

TODO: Rewrite the renderer to use 3x3 matricies or if possible fix the inverse of 3x2 matrices(It should just use a 3x3 matrix inverse). Maybe use it also inside camera. And in general makes the transforms in the renderer and camera more organized.

New level format.
Tools in game mode.
Editing entites in game mode. Writting by hand not auto generated imgui code.
Drawing polygons.
Revolute joints.
Spring joints.
Collision groups

Website that allows uploading and loading levels. The opening levels could be something like in Roblox. Uploading could be either done using the website or built in uploader which uses an api for uploading levels? The uploading from the program would also need a login system.
Should thumbnails be rendered on the client or server side?

PIV controllers
Soft body dynamics
Fluid dynamics.


Converting image metrics. Take the one metric and another metric (can try converting between different metrics). Take the ratio of the metrics and then scale the vector that is later used to sample the texture to "convert it to a different metric".
void mainImage( out vec4 fragColor, in vec2 fragCoord ) {
    vec2 uv = fragCoord/iResolution.xy;
    // Center (0, 0)
    uv -= 0.5f;
    
    float dC = (abs(uv.x) + abs(uv.y)) / 2.0f;
    // Try different scales < 1 and > 1
    //float dC = max(abs(uv.x), abs(uv.y)) * 2.0;
    //float dC = sin(uv.x * uv.x) + sin(uv.y * uv.y) * 1.0;
    float dE = length(uv);
    
    // Change * to /
    uv *= dE / dC;
    
    float m = 0.2f;
    vec3 col = vec3(mod(uv, vec2(m)) / m, 0.0);
    //vec3 col = texture(iChannel0, uv + 0.5f).xyz;
    fragColor = vec4(col, 1.0);
}

Shader system with instancing and constant buffer.
The user would create a .data file with an instance
ParticleInstance @Istance {
    Vec3 color;
}

It generates the vertex shader that takes the instance and return the values to the pixel shader. 
A pixel shader could also be generated one way would be to generate a include inside the main file so updating is easier.

#define parameters (Vec3 color)

#include <parameters.h>

float4 main parameters {

}

A better option might be to just create a header with a hlsl struct PixelInstance that gets included into both files and gets returned.

Generating the pixel shader main if it doesn't exist yet is also a good idea.

Renderer::createShader();
return the shader and creates a constant buffer that is mapped to the address of the constant buffer object inside the renderer. (or maybe store it in the shader struct?). The renderer would also need to have a dynamically resizable array (constant buffers aren't resizable) that would store the instances before rendering. When copying to the constant buffer copy directly from the dynamic array at <= constant buffer size incremenets).
In the renderer the dynamic arrays will be in a map from a address of the shader to an array of bytes.

The vertex shader will just draw a quad. Is there any reason the have a vertex shader constant buffer? Most things probably can be done using a pixel shader constant buffer.

Renderer::drawShader(Shader, Transform, Instance);

A shader would store both a vertex and a fragment shader and if needed constant buffers. Could make it a virtual type. Shader and ShaderWithConstantBuffer.

Could have a function preRender that sets all the needed state.

Textures could be an another type of state. Unfortunately they aren't handled the same as constant buffers.

Maybe save images in a different format to make it faster

Regular polygons in different metrics
d\left(A,\ B\right)=\left(\left|A.x-B.x\right|^{a}+\left|A.y-B.y\right|^{a}\right)^{\frac{1}{a}}
lim n -> -Infinity = min(a, b)
Use geometric constructions?
Line defined as a set of points that are equally distant too two points.